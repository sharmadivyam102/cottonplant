# -*- coding: utf-8 -*-
"""Cottondisease.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wkMayrAXhqY84vw05kQR2WP5aiFL4wVc

Importing drive on google colab
"""

from google.colab import drive
drive.mount('/content/drive')

"""Unzipping the training images folder from drive"""

!unzip '/content/drive/My Drive/train-20200930T101436Z-001.zip'

"""Unzipping the val images of folder """

!unzip "/content/drive/MyDrive/val-20200930T101213Z-001.zip"

"""unzipping the test images folder """

!unzip "/content/drive/MyDrive/test-20201128T174942Z-001.zip"

"""Importing Libraries """

import keras 
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt

"""Train and Test datapath """

train_data_path = "/content/train"
test_data_path = "/content/val"

"""Preparing the training data by rescaling the image , providing the target size """

training_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40,width_shift_range=0.2, shear_range=0.2, height_shift_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')

training_data = training_datagen.flow_from_directory(train_data_path, target_size=(150,150), batch_size = 32, class_mode = 'binary')

"""No. of Training Classes """

training_data.class_indices

"""Preparing the test dataset """

valid_datagen = ImageDataGenerator(rescale=1./255)

valid_data = valid_datagen.flow_from_directory(test_data_path, target_size = (150,150), batch_size = 32, class_mode = 'binary')

model_path = '/content/drive/My Drive/cott_dis.h5'
checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

"""Defining the architecture of the model """

cnn_model = keras.models.Sequential([
                                     keras.layers.Conv2D(filters=32, kernel_size=3, input_shape = [150, 150, 3]),
                                     keras.layers.MaxPooling2D(pool_size=(2,2)),
                                     keras.layers.Conv2D(filters=64, kernel_size=3),
                                     keras.layers.MaxPooling2D(pool_size=(2,2)),
                                     keras.layers.Conv2D(filters=128, kernel_size=3),
                                     keras.layers.MaxPooling2D(pool_size=(2,2)),
                                     keras.layers.Conv2D(filters=256, kernel_size=3),
                                     keras.layers.MaxPooling2D(pool_size=(2,2)),

                                     keras.layers.Dropout(0.5),
                                     keras.layers.Flatten(),
                                     keras.layers.Dense(units=128, activation='relu'),
                                     keras.layers.Dropout(0.1),
                                     keras.layers.Dense(units=256, activation='relu'),
                                     keras.layers.Dropout(0.25),
                                     keras.layers.Dense(units=4, activation='softmax')
])

"""Compiling the model , providing it a optimizer with learning rate and defining the loss """

cnn_model.compile(optimizer=Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

"""Summary of the model """

cnn_model.summary()

"""Training the model """

history = cnn_model.fit(training_data, epochs=100, verbose=1, validation_data=valid_data, callbacks=callbacks_list)

"""Saving the model """

model_path2 = "/content/drive/My Drive/cott_dis.h5"
cnn_model.save(model_path2)

"""Comparing validation accuracy with epoch"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

from keras.models import load_model

model = load_model('/content/drive/MyDrive/cott_dis.h5')

import numpy as np
from keras.preprocessing import image
test_image = image.load_img('/content/test/diseased cotton leaf/dis_leaf (124).jpg', target_size = (150, 150, 3))
test_image = image.img_to_array(test_image)
test_image = np.expand_dims(test_image, axis = 0)
result = model.predict(test_image)

if result[0][0] == 1:
  print("Disease cotton leaf")
elif result[0][1] == 1:
  print("Disease cotton plant")
elif result[0][2] == 1:
  print("fresh cotton leaf")
else:
  print("fresh cotton plant")